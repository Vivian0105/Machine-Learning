# -*- coding: utf-8 -*-
"""Housenumber.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j6eMbP0uDL_gMJe88mYXrlh88zUuyeCX
"""

import cv2
import os
from matplotlib import pyplot as plt
import numpy as np
from scipy import ndimage
from scipy.io import loadmat
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset,DataLoader,TensorDataset
import torch.nn as nn
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import torch.nn.functional as F
from torch.optim import lr_scheduler
from skimage.measure import regionprops
import copy


def preprocessing(img):
    h,w,_ = img.shape
    window= int(min(h,w)/100)
    k=cv2.getGaussianKernel(window,int(0.4*window))
    k=k.T*k
    img=cv2.filter2D(img,-1,k)
    if h/w>=1:
      img=cv2.resize(img,(int(w/h*750),750))
    else:
      img=cv2.resize(img,(750,int(h/w*750)))
    return img

# get mser bboxes and delete repeat boxes
def MSER_BOX(img):
    mser=cv2.MSER_create(_delta=6,_min_area=100, _max_area=7500,_max_variation = 0.15)
    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    regions, bboxes = mser.detectRegions(gray)
    hulls = [cv2.convexHull(p.reshape(-1, 1, 2)) for p in regions]
    filter_box=[]
    for i in range(len(bboxes)):
        box=bboxes[i]
        x,y,w,h=box
        area=len(regions[i])
        boxarea=float(w*h)
        convexarea=cv2.contourArea(hulls[i])
        if convexarea==0:
            continue
        occupy_rate=area/boxarea
        solidity=area/convexarea
        if w/h<1 and h/w<4 and occupy_rate<0.9 and occupy_rate>0.1 and solidity>0.1 and solidity<0.9:
            filter_box.append(box)
    if len(filter_box)==0:
      return []        
    filter_box=np.array(filter_box)
    filter_box = np.unique(filter_box, axis=0)
    filter_box2=[]
    processing_box=[]
    for box in filter_box:
      x,y,w,h=box
      if len(processing_box)==0:
        processing_box.append(box)
      else:
        average_box=np.array(processing_box).mean(axis=0)
        average_x,average_y,average_w,average_h=average_box
        if (average_x-x)**2+(average_y-y)**2< (0.3*average_w)**2+(0.3*average_h)**2 and (average_w-w)**2+(average_h-h)**2<(0.3*average_w)**2+(0.3*average_h)**2:
          processing_box.append(box)
        elif (average_x-x)**2+(average_y-y)**2< (0.3*average_w)**2+(0.3*average_h)**2 and (average_w-w)**2+(average_h-h)**2>(0.3*average_w)**2+(0.3*average_h)**2:
          continue
        else:
          filter_box2.append(average_box.astype(int))
          processing_box=[box]
    average_box=np.array(processing_box).mean(axis=0)      
    filter_box2.append(average_box.astype(int))
    return filter_box2

# Digit Detection
def digit_detection(filter_box2,img,model,imgname):
    vis=img.copy()
    test_areas=[]
    detected=[]
    for i in range(len(filter_box2)):
        box=filter_box2[i]
        x,y,w,h=box
        padding=int((h-w)/2)
        if x-padding>=0 and x-padding+h<img.shape[1]:
            target_area=img[y:y+h, x-padding:x-padding+h,:]
            target_area = cv2.resize(target_area,(224,224))
            target_area=(target_area-127.5)/127.5
            target_area=np.moveaxis(target_area,2,0)
            target_area=np.array([target_area],dtype=np.float32)
            target_area=torch.from_numpy(target_area)
            target_area=target_area.to(device)
            outputs=model(target_area)
            _,predicted=torch.max(outputs,1)
            predicted=predicted.item()
            if predicted!=0:
                if predicted==10:
                  predicted=0
                cv2.putText(vis,str(predicted),(x-padding,y),cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255))
                detected.append([x,y,w,h,predicted])
    if len(detected)==0:
      return []
    detected=np.array(detected)
    detected=detected[np.argsort(detected[:,0])]            
    cv2.imwrite("Detected_Digits_"+imgname,vis)
    return detected

# Combine digits into numbers
def combinedigit(img, detected):
    detected_patch=[]
    detected_number=[]
    back_up_detected=[]
    while True:
      for detect_info in detected:
        x,y,w,h,d=detect_info
        padding=int((h-w)/2)
        left_x=x-padding
        right_x=x+w+padding
        if len(detected_patch)==0:
          detected_patch.append([left_x,right_x,y,w,h,d])
        else:
          _,_,_,average_w,average_h,_=np.array(detected_patch).mean(axis=0)
          previous_left_x,previous_right_x,previous_y,previous_w,previous_h,previous_d=detected_patch[-1]
          if abs(previous_left_x-left_x)<(previous_w+w)/4 and abs(previous_y-y)<(previous_h+h)/6 and previous_d==d:
            new_left_x=int((previous_left_x+left_x)/2)
            new_right_x=int((previous_right_x+right_x)/2)
            new_y=int((previous_y+y)/2)
            new_w=int((previous_w+w)/2)
            new_h=int((previous_h+h)/2)
            detected_patch[-1]=[new_left_x,new_right_x,new_y,new_w,new_h,d]
          elif left_x<=previous_right_x and (w-average_w)**2<(average_w)**2 and (h-average_h)**2<(average_h/3)**2 and (previous_y-y)**2< (2*average_h)**2:
            detected_patch.append([left_x,right_x,y,w,h,d])
          else:
            back_up_detected.append(detect_info)
      n=len(detected_patch)
      number=0
      for i in range(n):
        digit=detected_patch[i][-1]
        number+=digit*10**(n-i-1)
      detected_number.append([detected_patch[0][0],detected_patch[0][2],number])  
      detected=copy.deepcopy(back_up_detected)
      back_up_detected=[]
      detected_patch=[]
      if len(detected)==0:
          break
    return detected_number

def showresult(detected_number,imgname):
    vis=img.copy()
    for detect_number in detected_number:
      x,y,number=detect_number
      print("Number %i is detected."%(number))
      cv2.putText(vis,str(number),(x,y),cv2.FONT_HERSHEY_SIMPLEX, 2, (100,100,255),3)
    cv2.imwrite(imgname,vis)


device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model=torchvision.models.vgg16(pretrained=True)
model.classifier[-1]=nn.Linear(4096, 11)
model.load_state_dict(torch.load('best_vgg_model_allversion.pth',map_location=torch.device('cpu')))
model = model.to(device)
model.eval()
path="frontdoor"
i=1
for file in os.listdir(path):
    print("\nprocessing "+file)
    img=cv2.imread(os.path.join(path,file))
    img=preprocessing(img)
    filter_box2=MSER_BOX(img)
    if len(filter_box2)==0:
      print("No digit box Found.")
      continue
    detected=digit_detection(filter_box2,img,model,file)
    if len(detected)==0:
      print("No digit Found.")
      continue
    detected_number=combinedigit(img, detected)
    showresult(detected_number,"graded_images/%i.png"%(i))
    i=i+1



